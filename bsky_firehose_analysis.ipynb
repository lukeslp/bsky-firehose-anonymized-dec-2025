{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Bluesky Firehose: Anonymized Posts (Dec 2025)\n",
    "\n",
    "Exploratory analysis of 101,040 Bluesky posts collected December 2–25, 2025 via the AT Protocol firehose.\n",
    "\n",
    "All author DIDs, post URIs, and thread relationships are SHA-256 hashed. Includes VADER sentiment, language detection, media flags, and thread structure.\n",
    "\n",
    "**Dataset**: [github.com/lukeslp/bsky-firehose-anonymized-dec-2025](https://github.com/lukeslp/bsky-firehose-anonymized-dec-2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "plt.rcParams['font.size'] = 11\n",
    "BLUE = '#1DA1F2'\n",
    "print('Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bluesky_posts.csv')\n",
    "print(f'Raw rows: {len(df):,}')\n",
    "\n",
    "# Drop trailing blank rows (89K blanks in export)\n",
    "df = df.dropna(subset=['text'])\n",
    "print(f'After dropping blanks: {len(df):,}')\n",
    "\n",
    "# Parse timestamps\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], utc=True)\n",
    "df['date'] = df['created_at'].dt.date\n",
    "\n",
    "# Parse JSON array columns\n",
    "for col in ['hashtags', 'mentions', 'links']:\n",
    "    df[col] = df[col].apply(lambda x: json.loads(x) if pd.notna(x) and x not in ('[]', '') else [])\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lang-header",
   "metadata": {},
   "source": [
    "## 2. Language Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "language",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_counts = df['language'].value_counts().head(12)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "bars = ax.bar(lang_counts.index, lang_counts.values, color=BLUE, edgecolor='white', linewidth=0.5)\n",
    "ax.set_title('Language Distribution (Top 12)', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.set_xlabel('Language Code')\n",
    "ax.set_ylabel('Post Count')\n",
    "ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "\n",
    "for bar, count in zip(bars, lang_counts.values):\n",
    "    pct = count / len(df) * 100\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 200, f'{pct:.1f}%', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(lang_counts.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sentiment-header",
   "metadata": {},
   "source": [
    "## 3. Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sentiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Categorical pie\n",
    "sent_counts = df['sentiment'].value_counts()\n",
    "colors = {'positive': '#4CAF50', 'neutral': '#9E9E9E', 'negative': '#F44336'}\n",
    "pie_colors = [colors.get(s, '#999') for s in sent_counts.index]\n",
    "ax1.pie(sent_counts.values, labels=sent_counts.index, autopct='%1.1f%%', colors=pie_colors, startangle=90)\n",
    "ax1.set_title('Sentiment Category', fontsize=13, fontweight='bold')\n",
    "\n",
    "# VADER score KDE\n",
    "scores = df['sentiment_score'].dropna()\n",
    "scores.plot.kde(ax=ax2, color=BLUE, linewidth=2)\n",
    "ax2.axvline(0, color='red', linestyle='--', alpha=0.5, label='Neutral boundary')\n",
    "ax2.axvline(scores.mean(), color='green', linestyle='--', alpha=0.7, label=f'Mean={scores.mean():.3f}')\n",
    "ax2.set_title('VADER Score Distribution', fontsize=13, fontweight='bold')\n",
    "ax2.set_xlabel('VADER Compound Score (-1 to 1)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-header",
   "metadata": {},
   "source": [
    "## 4. Posting Volume by Day (Dec 2–25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = df.groupby('date').size().reset_index(name='posts')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.fill_between(range(len(daily)), daily['posts'], alpha=0.3, color=BLUE)\n",
    "ax.plot(range(len(daily)), daily['posts'], color=BLUE, linewidth=2, marker='o', markersize=5)\n",
    "ax.set_xticks(range(len(daily)))\n",
    "ax.set_xticklabels([str(d) for d in daily['date']], rotation=45, ha='right', fontsize=9)\n",
    "ax.set_title('Daily Post Volume (December 2025)', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.set_ylabel('Posts')\n",
    "ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "media-header",
   "metadata": {},
   "source": [
    "## 5. Media Type Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "media",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_counts = df['embed_type'].fillna('none').value_counts()\n",
    "media_labels = [\n",
    "    ('has_images', 'Images'),\n",
    "    ('has_video', 'Video'),\n",
    "    ('has_link', 'Links'),\n",
    "]\n",
    "media_data = {label: df[col].sum() for col, label in media_labels}\n",
    "media_data['No Media'] = (~df[['has_images','has_video','has_link']].any(axis=1)).sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    media_data.values(),\n",
    "    labels=media_data.keys(),\n",
    "    autopct='%1.1f%%',\n",
    "    colors=['#2196F3','#FF9800','#4CAF50','#9E9E9E'],\n",
    "    startangle=90,\n",
    "    pctdistance=0.8\n",
    ")\n",
    "ax.set_title('Media Type Distribution', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "for k, v in media_data.items():\n",
    "    print(f'{k}: {v:,} ({v/len(df)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hashtags-header",
   "metadata": {},
   "source": [
    "## 6. Top Hashtags & Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hashtags",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hashtags = [tag.lstrip('#').lower() for tags in df['hashtags'] for tag in tags if tag]\n",
    "tag_counts = Counter(all_hashtags).most_common(20)\n",
    "\n",
    "all_mentions = [m for mentions in df['mentions'] for m in mentions if m]\n",
    "mention_counts = Counter(all_mentions).most_common(15)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "if tag_counts:\n",
    "    tags, counts = zip(*tag_counts)\n",
    "    ax1.barh(list(tags)[::-1], list(counts)[::-1], color='#AB47BC')\n",
    "    ax1.set_title(f'Top Hashtags (total: {len(all_hashtags):,})', fontsize=13, fontweight='bold')\n",
    "    ax1.set_xlabel('Occurrences')\n",
    "else:\n",
    "    ax1.text(0.5, 0.5, 'No hashtags found', ha='center', va='center', transform=ax1.transAxes)\n",
    "    ax1.set_title('Top Hashtags', fontsize=13, fontweight='bold')\n",
    "\n",
    "if mention_counts:\n",
    "    mentions, mcounts = zip(*mention_counts)\n",
    "    ax2.barh(list(mentions)[::-1], list(mcounts)[::-1], color='#26A69A')\n",
    "    ax2.set_title(f'Top Mentions (total: {len(all_mentions):,})', fontsize=13, fontweight='bold')\n",
    "    ax2.set_xlabel('Occurrences')\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'No mentions found', ha='center', va='center', transform=ax2.transAxes)\n",
    "    ax2.set_title('Top Mentions (anonymized)', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thread-header",
   "metadata": {},
   "source": [
    "## 7. Thread Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_reply = df['reply_parent_hash'].notna()\n",
    "is_thread_root = df['reply_root_hash'].notna() & df['reply_parent_hash'].isna()\n",
    "is_standalone = ~df['reply_root_hash'].notna()\n",
    "\n",
    "thread_data = {\n",
    "    'Standalone': is_standalone.sum(),\n",
    "    'Reply': is_reply.sum(),\n",
    "    'Thread root': is_thread_root.sum()\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(thread_data.keys(), thread_data.values(), color=['#607D8B','#1565C0','#00838F'])\n",
    "ax.set_title('Post Types: Standalone vs Thread Structure', fontsize=14, fontweight='bold', pad=12)\n",
    "ax.set_ylabel('Count')\n",
    "ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "\n",
    "for bar, count in zip(bars, thread_data.values()):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100, f'{count:,}\\n({count/len(df)*100:.1f}%)', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "text-header",
   "metadata": {},
   "source": [
    "## 8. Text Length Distributions by Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "text-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_langs = df['language'].value_counts().head(5).index.tolist()\n",
    "lang_subset = df[df['language'].isin(top_langs)]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for lang in top_langs:\n",
    "    subset = lang_subset[lang_subset['language'] == lang]\n",
    "    if len(subset) > 10:\n",
    "        subset['char_count'].clip(0, 400).plot.kde(ax=ax1, label=lang, linewidth=1.5)\n",
    "        subset['word_count'].clip(0, 100).plot.kde(ax=ax2, label=lang, linewidth=1.5)\n",
    "\n",
    "ax1.set_title('Character Count Distribution by Language', fontsize=13, fontweight='bold')\n",
    "ax1.set_xlabel('Character Count')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_title('Word Count Distribution by Language', fontsize=13, fontweight='bold')\n",
    "ax2.set_xlabel('Word Count')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nMedian character count by language:')\n",
    "print(lang_subset.groupby('language')['char_count'].median().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Bluesky Firehose Dec 2025 — Summary Statistics ===')\n",
    "print(f'Total posts: {len(df):,}')\n",
    "print(f'Unique authors: {df[\"author_did_hash\"].nunique():,}')\n",
    "print(f'Date range: {df[\"date\"].min()} to {df[\"date\"].max()}')\n",
    "print(f'Languages: {df[\"language\"].nunique()}')\n",
    "print(f'\\nSentiment breakdown:')\n",
    "for sent, count in df['sentiment'].value_counts().items():\n",
    "    print(f'  {sent}: {count:,} ({count/len(df)*100:.1f}%)')\n",
    "print(f'\\nMean VADER score: {df[\"sentiment_score\"].mean():.4f}')\n",
    "print(f'Posts with images: {df[\"has_images\"].sum():,} ({df[\"has_images\"].mean()*100:.1f}%)')\n",
    "print(f'Posts with links: {df[\"has_link\"].sum():,} ({df[\"has_link\"].mean()*100:.1f}%)')\n",
    "print(f'Replies: {df[\"reply_parent_hash\"].notna().sum():,} ({df[\"reply_parent_hash\"].notna().mean()*100:.1f}%)')"
   ]
  }
 ]
}